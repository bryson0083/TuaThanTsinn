# -*- coding: utf-8 -*-
"""
DPL001 - å°è‚¡æ•¸æ“šæ”¶é›†ç›¸é—œçš„ Prefect Flows
åŒ…å«å„ç¨®å°è‚¡æ•¸æ“šçš„è³‡æ–™æŠ“å–æµç¨‹
"""

import os
from datetime import datetime
from pathlib import Path
import json
import sys
# from dotenv import load_dotenv
import papermill as pm


# å°å…¥è‡ªå»ºå…¬ç”¨æ¨¡çµ„ - è¼‰å…¥æ™‚æœƒè‡ªå‹•åˆå§‹åŒ–ç’°å¢ƒè¨­å®š
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))
from TuaThanTsinn.proj_util_pkg.settings import settings

# å°å…¥ Prefect ç›¸é—œæ¨¡çµ„
from prefect import flow, task
from prefect.logging import get_run_logger

# è¨­å®šç›®éŒ„è·¯å¾‘
CURRENT_DIR = Path(__file__).parent
PROJECT_ROOT = CURRENT_DIR.parent


@task(name="åŸ·è¡Œå°è‚¡è‚¡ç¥¨ä»£ç¢¼è³‡è¨Šæ”¶é›†")
def run_dpl001_01_twstock_info_collect():
    """åŸ·è¡Œå°è‚¡è‚¡ç¥¨ä»£ç¢¼è³‡è¨Šæ”¶é›† - ä½¿ç”¨ papermill åŸ·è¡Œ collect_twstock_etf_list.ipynb"""

    logger = get_run_logger()
    logger.info("ğŸ” é–‹å§‹åŸ·è¡Œå°è‚¡è‚¡ç¥¨ä»£ç¢¼è³‡è¨Šæ”¶é›†...")
    
    try:
        # å®šç¾©æª”æ¡ˆè·¯å¾‘
        input_notebook = CURRENT_DIR / "collect_twstock_etf_list.ipynb"
        output_notebook = CURRENT_DIR / "collect_twstock_etf_list_executed.ipynb"

        # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
        output_dir = PROJECT_ROOT / "output" / "DPL001_å°è‚¡æ•¸æ“šæ”¶é›†"
        output_dir.mkdir(parents=True, exist_ok=True)

        logger.info(f"ğŸ““ åŸ·è¡Œ notebook: {input_notebook}")
        
        # ä½¿ç”¨ papermill åŸ·è¡Œ notebook
        pm.execute_notebook(
            input_path=str(input_notebook),
            output_path=str(output_notebook),
            parameters={
                # å¯ä»¥åœ¨é€™è£¡å‚³éåƒæ•¸çµ¦ notebook
                # ä¾‹å¦‚: 'analysis_date': datetime.now().strftime('%Y-%m-%d')
            },
            log_output=True,
            progress_bar=False
        )
        
        logger.info("âœ… Notebook åŸ·è¡Œå®Œæˆ")

        # å„²å­˜åŸ·è¡Œçµæœæ‘˜è¦
        summary_path = output_dir / f"{datetime.now().strftime('%Y%m%d_%H%M')}_DPL001_01_å°è‚¡è‚¡ç¥¨ä»£ç¢¼è³‡è¨Šæ”¶é›†_deploy.json"
        summary = {
            "analysis_time": datetime.now().isoformat(),
            "notebook_executed": str(output_notebook),
            "success": True
        }
        
        with open(summary_path, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ“Š åŸ·è¡Œæ‘˜è¦å·²å„²å­˜è‡³: {summary_path}")

        return {
            "method": "DPL001_01_å°è‚¡è‚¡ç¥¨ä»£ç¢¼è³‡è¨Šæ”¶é›†",
            "output_file": str(output_notebook),
            "analysis_time": datetime.now().isoformat(),
            "notebook_path": str(output_notebook)
        }

    except Exception as e:
        logger.error(f"âŒ DPL001_01_å°è‚¡è‚¡ç¥¨ä»£ç¢¼è³‡è¨Šæ”¶é›† ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        
        # å„²å­˜éŒ¯èª¤è³‡è¨Š
        error_summary = {
            "analysis_time": datetime.now().isoformat(),
            "error_message": str(e),
            "success": False
        }
        
        error_path = output_dir / f"{datetime.now().strftime('%Y%m%d_%H%M')}_DPL001_01_å°è‚¡è‚¡ç¥¨ä»£ç¢¼è³‡è¨Šæ”¶é›†_deploy_error.json"
        with open(error_path, 'w', encoding='utf-8') as f:
            json.dump(error_summary, f, ensure_ascii=False, indent=2)
            
        raise


@task(name="åŸ·è¡Œå°è‚¡æ”¶ç›¤è³‡è¨Šæ”¶é›†")
def run_dpl001_02_twstock_close_info_collect():
    """åŸ·è¡Œå°è‚¡æ”¶ç›¤è³‡è¨Šæ”¶é›† - ä½¿ç”¨ papermill åŸ·è¡Œ collect_å°è‚¡æ”¶ç›¤è³‡è¨Š.ipynb"""

    logger = get_run_logger()
    logger.info("ğŸ” é–‹å§‹åŸ·è¡Œå°è‚¡æ”¶ç›¤è³‡è¨Šæ”¶é›†...")
    
    try:
        # å®šç¾©æª”æ¡ˆè·¯å¾‘
        input_notebook = CURRENT_DIR / "collect_å°è‚¡æ”¶ç›¤è³‡è¨Š.ipynb"
        output_notebook = CURRENT_DIR / "collect_å°è‚¡æ”¶ç›¤è³‡è¨Š_executed.ipynb"

        # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
        output_dir = PROJECT_ROOT / "output" / "DPL001_å°è‚¡æ•¸æ“šæ”¶é›†"
        output_dir.mkdir(parents=True, exist_ok=True)

        logger.info(f"ğŸ““ åŸ·è¡Œ notebook: {input_notebook}")
        
        # ä½¿ç”¨ papermill åŸ·è¡Œ notebook
        pm.execute_notebook(
            input_path=str(input_notebook),
            output_path=str(output_notebook),
            parameters={
                # å¯ä»¥åœ¨é€™è£¡å‚³éåƒæ•¸çµ¦ notebook
                # ä¾‹å¦‚: 'analysis_date': datetime.now().strftime('%Y-%m-%d')
            },
            log_output=True,
            progress_bar=False
        )
        
        logger.info("âœ… Notebook åŸ·è¡Œå®Œæˆ")

        # å„²å­˜åŸ·è¡Œçµæœæ‘˜è¦
        summary_path = output_dir / f"{datetime.now().strftime('%Y%m%d_%H%M')}_DPL001_02_å°è‚¡æ”¶ç›¤è³‡è¨Šæ”¶é›†_deploy.json"
        summary = {
            "analysis_time": datetime.now().isoformat(),
            "notebook_executed": str(output_notebook),
            "success": True
        }
        
        with open(summary_path, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ“Š åŸ·è¡Œæ‘˜è¦å·²å„²å­˜è‡³: {summary_path}")

        return {
            "method": "DPL001_02_å°è‚¡æ”¶ç›¤è³‡è¨Šæ”¶é›†",
            "output_file": str(output_notebook),
            "analysis_time": datetime.now().isoformat(),
            "notebook_path": str(output_notebook)
        }

    except Exception as e:
        logger.error(f"âŒ DPL001_02_å°è‚¡æ”¶ç›¤è³‡è¨Šæ”¶é›† ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        
        # å„²å­˜éŒ¯èª¤è³‡è¨Š
        error_summary = {
            "analysis_time": datetime.now().isoformat(),
            "error_message": str(e),
            "success": False
        }
        
        error_path = output_dir / f"{datetime.now().strftime('%Y%m%d_%H%M')}_DPL001_02_å°è‚¡æ”¶ç›¤è³‡è¨Šæ”¶é›†_deploy_error.json"
        with open(error_path, 'w', encoding='utf-8') as f:
            json.dump(error_summary, f, ensure_ascii=False, indent=2)
            
        raise


@task(name="åŸ·è¡Œé‰…äº¨ç¶²é¡Œæä¾†æºæ”¶é›†")
def run_dpl001_03_twstock_topic_collect():
    """åŸ·è¡Œé‰…äº¨ç¶²é¡Œæä¾†æºæ”¶é›† - ä½¿ç”¨ papermill åŸ·è¡Œ collect_é‰…äº¨ç¶²é¡Œæä¾†æº.ipynb"""

    logger = get_run_logger()
    logger.info("ğŸ” é–‹å§‹åŸ·è¡Œé‰…äº¨ç¶²é¡Œæä¾†æºæ”¶é›†...")
    
    try:
        # å®šç¾©æª”æ¡ˆè·¯å¾‘
        input_notebook = CURRENT_DIR / "collect_é‰…äº¨ç¶²é¡Œæä¾†æº.ipynb"
        output_notebook = CURRENT_DIR / "collect_é‰…äº¨ç¶²é¡Œæä¾†æº_executed.ipynb"

        # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
        output_dir = PROJECT_ROOT / "output" / "DPL001_å°è‚¡æ•¸æ“šæ”¶é›†"
        output_dir.mkdir(parents=True, exist_ok=True)

        logger.info(f"ğŸ““ åŸ·è¡Œ notebook: {input_notebook}")
        
        # ä½¿ç”¨ papermill åŸ·è¡Œ notebook
        pm.execute_notebook(
            input_path=str(input_notebook),
            output_path=str(output_notebook),
            parameters={
                # å¯ä»¥åœ¨é€™è£¡å‚³éåƒæ•¸çµ¦ notebook
                # ä¾‹å¦‚: 'analysis_date': datetime.now().strftime('%Y-%m-%d')
            },
            log_output=True,
            progress_bar=False
        )
        
        logger.info("âœ… Notebook åŸ·è¡Œå®Œæˆ")

        # å„²å­˜åŸ·è¡Œçµæœæ‘˜è¦
        summary_path = output_dir / f"{datetime.now().strftime('%Y%m%d_%H%M')}_DPL001_03_é‰…äº¨ç¶²é¡Œæä¾†æºæ”¶é›†_deploy.json"
        summary = {
            "analysis_time": datetime.now().isoformat(),
            "notebook_executed": str(output_notebook),
            "success": True
        }
        
        with open(summary_path, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ“Š åŸ·è¡Œæ‘˜è¦å·²å„²å­˜è‡³: {summary_path}")

        return {
            "method": "DPL001_03_é‰…äº¨ç¶²é¡Œæä¾†æºæ”¶é›†",
            "output_file": str(output_notebook),
            "analysis_time": datetime.now().isoformat(),
            "notebook_path": str(output_notebook)
        }

    except Exception as e:
        logger.error(f"âŒ DPL001_03_é‰…äº¨ç¶²é¡Œæä¾†æºæ”¶é›† ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        
        # å„²å­˜éŒ¯èª¤è³‡è¨Š
        error_summary = {
            "analysis_time": datetime.now().isoformat(),
            "error_message": str(e),
            "success": False
        }
        
        error_path = output_dir / f"{datetime.now().strftime('%Y%m%d_%H%M')}_DPL001_03_é‰…äº¨ç¶²é¡Œæä¾†æºæ”¶é›†_deploy_error.json"
        with open(error_path, 'w', encoding='utf-8') as f:
            json.dump(error_summary, f, ensure_ascii=False, indent=2)
            
        raise


@flow(name="DPL001_å°è‚¡æ•¸æ“šæ”¶é›†", log_prints=True)
def do_dpl001_flow():
    """ DPL001_å°è‚¡æ•¸æ“šæ”¶é›†æµç¨‹ """
    
    logger = get_run_logger()
    logger.info("ğŸš€ é–‹å§‹åŸ·è¡Œ DPL001_å°è‚¡æ•¸æ“šæ”¶é›† æµç¨‹")
    
    try:
        # ä¸¦è¡ŒåŸ·è¡Œå„ç¨®é¸è‚¡åˆ†æ
        dpl001_01_twstock_info_result = run_dpl001_01_twstock_info_collect()
        dpl001_02_twstock_close_info_result = run_dpl001_02_twstock_close_info_collect()

        # æ”¶é›†æ‰€æœ‰çµæœ
        all_results = [dpl001_01_twstock_info_result, dpl001_02_twstock_close_info_result]

        logger.info("ğŸ‰ DPL001_å°è‚¡æ•¸æ“šæ”¶é›† æµç¨‹å®Œæˆï¼")
        return {
            "status": "success", 
            "analysis_results": all_results,
            "analysis_complete": True
        }
        
    except Exception as e:
        logger.error(f"âŒ DPL001_å°è‚¡æ•¸æ“šæ”¶é›† æµç¨‹ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return {
            "status": "failed", 
            "error": str(e),
            "analysis_complete": False
        }


@flow(name="DPL001_å°è‚¡æ•¸æ“šæ”¶é›†_é‰…äº¨ç¶²é¡Œæä¾†æº", log_prints=True)
def do_dpl001_flow_topic():
    """ DPL001_å°è‚¡æ•¸æ“šæ”¶é›†_é‰…äº¨ç¶²é¡Œæä¾†æºæµç¨‹ """
    
    logger = get_run_logger()
    logger.info("ğŸš€ é–‹å§‹åŸ·è¡Œ DPL001_å°è‚¡æ•¸æ“šæ”¶é›†_é‰…äº¨ç¶²é¡Œæä¾†æº æµç¨‹")
    
    try:
        # ä¸¦è¡ŒåŸ·è¡Œå„ç¨®é¸è‚¡åˆ†æ
        dpl001_03_twstock_topic_result = run_dpl001_03_twstock_topic_collect()

        # æ”¶é›†æ‰€æœ‰çµæœ
        all_results = [dpl001_03_twstock_topic_result]

        logger.info("ğŸ‰ DPL001_å°è‚¡æ•¸æ“šæ”¶é›†_é‰…äº¨ç¶²é¡Œæä¾†æº æµç¨‹å®Œæˆï¼")
        return {
            "status": "success", 
            "analysis_results": all_results,
            "analysis_complete": True
        }
        
    except Exception as e:
        logger.error(f"âŒ DPL001_å°è‚¡æ•¸æ“šæ”¶é›†_é‰…äº¨ç¶²é¡Œæä¾†æº æµç¨‹ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return {
            "status": "failed", 
            "error": str(e),
            "analysis_complete": False
        }


if __name__ == "__main__":
    # ç›´æ¥åŸ·è¡Œæ­¤æª”æ¡ˆæ™‚ï¼ŒåŸ·è¡Œ DPL001_å°è‚¡æ•¸æ“šæ”¶é›† æµç¨‹
    result = do_dpl001_flow()
    print(f"Flow execution result: {result}")
    